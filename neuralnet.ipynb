{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtkYAsJgsD09"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om27VYNcssSA",
        "outputId": "925f6903-78b2-4654-d09d-c57ded962456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBazvHuhsD0-"
      },
      "outputs": [],
      "source": [
        "# Data path\n",
        "train_path = '/content/drive/My Drive/train.csv'\n",
        "test_path = '/content/drive/My Drive/test.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4rsj-32sD0_"
      },
      "outputs": [],
      "source": [
        "# Read CSV file into a dataframe\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "original_test_df = pd.read_csv(test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_P8306fUsD0_"
      },
      "outputs": [],
      "source": [
        "# Convert dataframe to numpy array\n",
        "train_array = train_df.values\n",
        "test_array = test_df.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqfY8FKdsD0_",
        "outputId": "34069605-95bb-452a-8800-398220457877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5343, 21)\n"
          ]
        }
      ],
      "source": [
        "print(train_array.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWJ8yfEEsD0_"
      },
      "outputs": [],
      "source": [
        "# Drop the customerID column\n",
        "train_df = train_df.drop('customerID', axis=1)\n",
        "\n",
        "# Fill in missing values\n",
        "train_df['TotalCharges'].fillna(train_df['TotalCharges'].median(), inplace=True)\n",
        "\n",
        "\n",
        "# Dictionary to hold the LabelEncoders\n",
        "label_encoders = {}\n",
        "\n",
        "# Encode categorical features\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "categorical_features = [column for column in train_df.columns if train_df[column].dtype == 'object']\n",
        "for column in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    train_df[column] = le.fit_transform(train_df[column])\n",
        "    label_encoders[column] = le\n",
        "\n",
        "# Seperate the features and the target\n",
        "X = train_df.drop('Discontinued', axis=1)\n",
        "y = train_df['Discontinued']\n",
        "\n",
        "# Split the data into training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "\n",
        "# Convert the numpy arrays to tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val.values, dtype=torch.float32)\n",
        "\n",
        "# Create a dataloader\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQb1fCf9sD1A",
        "outputId": "53c5f1ef-fbe0-4687-bcc3-f8d0f8d5f263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.5426204800605774\n",
            "Epoch 2, Loss: 0.5018996000289917\n",
            "Epoch 3, Loss: 0.396027147769928\n",
            "Epoch 4, Loss: 0.30742505192756653\n",
            "Epoch 5, Loss: 0.43631598353385925\n",
            "Epoch 6, Loss: 0.44387638568878174\n",
            "Epoch 7, Loss: 0.40216830372810364\n",
            "Epoch 8, Loss: 0.384438693523407\n",
            "Epoch 9, Loss: 0.3928157687187195\n",
            "Epoch 10, Loss: 0.4448930621147156\n",
            "Epoch 11, Loss: 0.3709146976470947\n",
            "Epoch 12, Loss: 0.26193302869796753\n",
            "Epoch 13, Loss: 0.3507553040981293\n",
            "Epoch 14, Loss: 0.3616562783718109\n",
            "Epoch 15, Loss: 0.433519184589386\n",
            "Epoch 16, Loss: 0.3560882806777954\n",
            "Epoch 17, Loss: 0.5302623510360718\n",
            "Epoch 18, Loss: 0.2673327922821045\n",
            "Epoch 19, Loss: 0.3325665295124054\n",
            "Epoch 20, Loss: 0.31982773542404175\n",
            "Accuracy: 0.7932647333956969\n",
            "0.815541751175545\n"
          ]
        }
      ],
      "source": [
        "# Create a neural network\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(19, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "model = NeuralNetwork()\n",
        "\n",
        "# Loss function and optimizer\n",
        "loss = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(20):\n",
        "    for batch in train_loader:\n",
        "        features, target = batch\n",
        "        optimizer.zero_grad()\n",
        "        output = model(features)\n",
        "        loss_value = loss(output, target.view(-1, 1))\n",
        "        loss_value.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss_value.item()}')\n",
        "\n",
        "# Evaluate the model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        features, target = batch\n",
        "        output = model(features)\n",
        "        pred = torch.round(output)\n",
        "        total += target.size(0)\n",
        "        correct += (pred == target.view(-1, 1)).sum().item()\n",
        "print(f'Accuracy: {correct / total}')\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'model.pth')\n",
        "torch.save(scaler, 'scaler.pth')\n",
        "torch.save(label_encoders, 'label_encoders.pth')\n",
        "\n",
        "# calculate ROC AUC\n",
        "from sklearn.metrics import roc_auc_score\n",
        "y_pred = model(X_val).detach().numpy()\n",
        "print(roc_auc_score(y_val, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAc1SfzOsD1A"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "test_df = test_df.drop('customerID', axis=1)\n",
        "\n",
        "# Fill in missing values\n",
        "test_df['TotalCharges'].fillna(test_df['TotalCharges'].median(), inplace=True)\n",
        "\n",
        "# Exclude 'Discontinued' column\n",
        "categorical_features = [column for column in categorical_features if column != 'Discontinued']\n",
        "\n",
        "# Use saved label encoders to encode the categorical features\n",
        "for column in categorical_features:\n",
        "    le = label_encoders[column]\n",
        "    test_df[column] = le.transform(test_df[column])\n",
        "\n",
        "# Scale the features\n",
        "X_test = test_df\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert the numpy arrays to tensors\n",
        "X_test = torch.tensor(X_test_scaled, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5To-Z1uUsD1A",
        "outputId": "b2b25847-f4c9-45f5-b9ae-a7415822ae60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5738319 ]\n",
            " [0.23072152]\n",
            " [0.91608775]\n",
            " ...\n",
            " [0.01121193]\n",
            " [0.00475039]\n",
            " [0.29760617]]\n"
          ]
        }
      ],
      "source": [
        "# Predict probabilities\n",
        "with torch.no_grad():\n",
        "    predictions = model(X_test).detach().numpy()\n",
        "\n",
        "print(predictions)\n",
        "\n",
        "# Save the predictions\n",
        "output_df = pd.DataFrame({\n",
        "    'ID': original_test_df['customerID'],\n",
        "    'TARGET': predictions.flatten()\n",
        "})\n",
        "\n",
        "output_df.to_csv('predictions.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}